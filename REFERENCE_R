# DSCI 100 function reference sheet for R

This reference sheet contains the key objects that we use in DSCI 100, and a
brief syntax example for each of the main packages. During the closed book
exams, you will still have access to this page, so get familiar with it already
now. There is no guarantee that every function or parameter in the textbook is
covered here, but if you think there is something missing, please let us know
and we can consider adding it.

Note that we have only described use cases relevant to DSCI 100.
Sometimes we have included the exact parameter name of a function,
e.g. `print(x)`,
other times we have opted to included a more descriptive name,
e.g. `mean(column)`.

## Base R Operations

| Function             | Description                                                |
| -------------------- | ---------------------------------------------------------- |
| `abs(x)`             | Convert numeric value(s) to absolute value                 |
| `as.data.frame(x)`   | Converts an object to a data frame                         |
| `as.numeric(x)`      | Converts a variable to a numeric data type                 |
| `c(1,2,3)`           | Combines values into a vector or list in R                 |
| `is.na(column)`      | Detect missing (NA) values in a vector or data frame       |
| `dim(column)`        | Returns dimensions (rows and columns) of an R object       |
| `max(column)`        | Returns maximum value in a numeric vector                  |
| `mean(column)`       | Returns average value in a numeric vector                  |
| `median(column)`     | Returns the median value in a numeric vector               |
| `min(column)`        | Returns minimum value in a numeric vector                  |
| `n()`                | Counts the number of rows in a table's group               |
| `names(tbl)`         | Assigns or retrieves names of elements in an R object      |
| `ncol(tbl)`          | Returns the number of columns in a matrix/data frame       |
| `nrow(tbl)`          | Returns the number of rows in a matrix/data frame          |
| `print(x)`           | Displays specified object's value                          |
| `round(num, digits)` | Rounds a number to specified decimals                      |
| `sd(column)`         | Calculates standard deviation for numeric data             |
| `seq(from, to, by)`  | Generates a sequence of numbers                            |
| `sum(column)`        | Calculates the sum of numeric values in a vector or matrix |
| `sort(df)`           | Sorts a vector or data frame in ascending order            |
| `sqrt(num)`          | Computes the square root of a numeric value                |

## Operators

| Function             | Description                                            |
| -------------------- | ------------------------------------------------------ |
| `==`                 | Compares two values and returns TRUE if they are equal |
| `%in%`               | Checks if elements on the left side are in the right   |
| `!`                  | Negates a logical value (!TRUE is FALSE)               |
| `&`                  | Performs element-wise logical AND operations           |
| <code>&#124;</code>  | Represents the OR logical operator                     |
| <code>&#124;></code> | Pipe operator, which passes data from left to right    |

## Data Reading

| Function                                       | Description                                    |
| ---------------------------------------------- | ---------------------------------------------- |
| `download.file(url, destfile)`                 | Download a file from the web                   |
| `read_csv(filepath)`                           | Reads comma-separated values into a data frame |
| `read_csv2(filepath)`                          | Reads CSV files with semicolon delimiter       |
| `read_delim(filepath, delim, skip, col_names)` | Reads data from a delimited text file          |
| `read_excel(filepath)`                         | Reads Excel files into R data frames           |
| `read_html(filepath)`                          | Reads and parses HTML web pages                |
| `read_tsv(filepath)`                           | Reads tab-separated values into a data frame   |
| `write_csv(tbl, filepath)`                     | Writes data to a CSV file                      |

Database functions:

| Function                            | Description                                         |
| ----------------------------------- | --------------------------------------------------- |
| `collect(database_table)`           | Convert a database table to a tibble                |
| `dbConnect(database, dbname)`       | Establishes a connection to a database              |
| `dbListTables(dbConnect_object)`    | Lists tables in a database connection               |
| `RPostgres::Postgres()`             | Connects to and interacts with PostgreSQL databases |
| `RSQLite::SQLite()`                 | Access and manage SQLite database connections       |
| `tbl(dbConnect_object, table_name)` | Creates a data frame from a data source             |

## Data Wrangling

| Function                                                           | Description                                                           |
| ------------------------------------------------------------------ | --------------------------------------------------------------------- |
| `across(column_range, function)`                                   | Apply the given function to each column in the specified column range |
| `arrange(tibble, columns_as_arguments)`                            | Order rows by the values of the given columns (default is increasing) |
| `colnames(tbl)`                                                    | Get a list of column names from a tibble                              |
| `desc(column)`                                                     | Sort a column (or numeric vector) in descending order                 |
| `everything()`                                                     | Select all variables (used in other functions)                        |
| `filter(tbl, condition)`                                           | Keep rows that match a condition                                      |
| `fct_reorder(factor_column, ordering_column, .desc = FALSE)`       | Reorder a column by sorting according to another column               |
| `group_by(tbl, columns_as_arguments)`                              | Group a tibble by the list of columns provided                        |
| `map(tbl, function)`                                               | Apply the given function to each column, creating a list              |
| `map_chr(tbl, function)`                                           | Apply the given function to each column, creating a character vector  |
| `map_df(tbl, function)`                                            | Apply the given function to each column, creating a data frame        |
| `mutate(tbl, column_name = ...)`                                   | Create or modify a column in a tibble                                 |
| `pivot_longer(tbl, column_range, names_to = ..., values_to = ...)` | Move values from column names to cells                                |
| `pivot_wider(tbl, names_from = ..., values_from = ...)`            | Move variables from cells to column names                             |
| `pull(tbl, variable)`                                              | Extract a single variable from a tibble                               |
| `rowwise(tbl)`                                                     | Organize a tibble row-by-row for other functions                      |
| `select(tbl, columns_as_arguments)`                                | Keep the given columns                                                |
| `semi_join(tbl, joining_tbl)`                                      | Keep rows that have matching values in joining_tbl                    |
| `separate(tbl, column, into, sep)`                                 | Split values in a column into new columns based on a separator        |
| `summarize(tbl, summaries_as_arguments)`                           | Compute summary statistics on columns                                 |
| `ungroup(tbl)`                                                     | Undo the effect of group_by()                                         |

Functions used to convert one type to another:

| Function                        | Description                                         |
| ------------------------------- | --------------------------------------------------- |
| `as_datetime(formatted_string)` | Convert a string to a Date object                   |
| `as_factor(column)`             | Convert a column to a factor / categorical variable |
| `as_tibble(object)`             | Convert an object to a tibble                       |

Slicing functions:

| Function                             | Description                                            |
| ------------------------------------ | ------------------------------------------------------ |
| `head(tbl)`                          | Get the first 6 rows of a tibble                       |
| `slice(tbl, row_range)`              | Keep rows in the given range                           |
| `slice_max(tbl, ordering_column, n)` | Keep the n rows with the largest values of a variable  |
| `slice_min(tbl, ordering_column, n)` | Keep the n rows with the smallest values of a variable |
| `unique(tbl)`                        | Delete duplicate rows                                  |
| `tail(tbl)`                          | Get the last 6 rows of a tibble                        |

Functions used to manipulate strings:

| Function                                        | Description                                            |
| ----------------------------------------------- | ------------------------------------------------------ |
| `str_extract(string, pattern)`                  | Extract the first substring matching the given pattern |
| `str_replace_all(string, pattern, replacement)` | Replace all substrings matching the given pattern      |
| `tolower(string)`                               | Convert a string to all-lowercase                      |
| `toupper(string)`                               | Convert a string to all-uppercase                      |

## Visualization

A typical `ggplot2` syntax for creating a new plot looks something like this:

```
library(tidyverse)

my_data |> ggplot(aes(x = column1, y = column2)) +
  geom_point()
```

| Function                        | Description                                                                          |
| ------------------------------- | ------------------------------------------------------------------------------------ |
| `aes(x, y, ...)`                | Specifies how variables in the data are mapped to properties of the plot             |
| `element_text(size, colour)`    | Used with `theme` system to control text size, colour, etc.                          |
| `facet_grid(rows, cols)`        | Creates matrix panels with plots based on specified rows or cols variable            |
| `facet_wrap(facets)`            | Creates a ribbon of panels wrapped in 2d using specified facets                      |
| `ggmap(map)`                    | Used to display visual maps from Google Maps or Stamen Maps                          |
| `ggpairs(tbl)`                  | Plots each variables against all the other variables in a scatterplot matrix         |
| `ggplot(tbl, mapping)`          | Initialize a `ggplot` object, specifying the data and aesthetic mapping for the plot |
| `ggsave(filename, plot)`        | Saves specified plot with given filename to device                                   |
| `ggtitle(title)`                | Adds specified title to the plot                                                     |
| `labs(x, y, fill, colour, ...)` | Modifies labels on the plot, specifying what the new labels should be                |
| `scale_color_manual(values)`    | Manually change the colour for plots by specifying the values                        |
| `scale_fill_brewer(palette)`    | Changes the fill colour palette to the specified palette                             |
| `scale_fill_distiller(palette)` | Changes the fill colour palette for continuous scales                                |
| `scale_x_continuous(limits)`    | Customize x-axis scales for continuous x variables with specified options            |
| `scale_x_date(limits, breaks)`  | Customize the x-axis scales for date or time variables in a plot                     |
| `scale_y_continuous(limits)`    | Customize y-axis scales for continuous y variables with specified options            |
| `theme(text) `                  | Used to modify the non-data components of the plot with specified options            |
| `xlab(label)`                   | Modifies the x-axis label to the specified label                                     |
| `xlim(lo, hi)`                  | Displays only the specified range on the x-axis of the plot                          |
| `ylab(label)`                   | Modifies the y-axis label to the specified label                                     |
| `ylim(lo, hi)`                  | Displays only the specified range on the y-axis of the plot                          |
| `vars(columns_as_arguments)`    | Choose variables to split a plot on in `facet_grid()`                                |

Commonly used geometric objects are listed below.

| Function                         | Description                                                                   |
| -------------------------------- | ----------------------------------------------------------------------------- |
| `geom_abline(slope, intercept)`  | Adds a diagonal line to the plot with specified intercept and slope           |
| `geom_bar(stat)`                 | Used to create bar graphs with specified `stat` (often "identity" or "count") |
| `geom_density()`                 | Used to create a smoothened line version of a histogram                       |
| `geom_freqpoly()`                | Used to create a lined (not smooth) version of a histogram                    |
| `geom_histogram(bins, binwidth)` | Creates histogram plots with a specified number of bins and bin width         |
| `geom_line()`                    | Adds lines to connect data points in the order of the x-axis                  |
| `geom_point()`                   | Used to create a scatterplot graphs                                           |
| `geom_segment(x, y, xend, yend)` | Draws a straight line on plot connecting (x, y) to (xend, yend)               |
| `geom_vline(xintercept)`         | Adds a vertical line to the plot at the specified x-intercept                 |

## Modeling

A typical `tidymodels` workflow looks something like this:

```
library(tidymodels)

knn_fit <- workflow() |>
  add_recipe(my_recipe) |>
  add_model(knn_spec) |>
  fit(data = my_data)

pred <- predict(knn_fit, new_data)
```

The functions below are relevant for Week 7 (`classification1`) and beyond.

| Function                                   | Description                                    |
| ------------------------------------------ | ---------------------------------------------- |
| `add_model(workflow, model_spec)`          | Add a model to a workflow                      |
| `add_recipe(workflow, model_recipe)`       | Add a recipe to a workflow                     |
| `add_row(data, col1, col2)`                | Add rows to a dataframe                        |
| `all_predictors()`                         | Select all predictors                          |
| `bake(recipe, data)`                       | Applies the results of prep() into the data    |
| `bind_cols(df1, df2)`                      | Combine multiple dataframes together           |
| `dist(data, method)`                       | Computes and returns the distance matrix       |
| `as_factor(data, variable)`                | Converts a variable to a factor type           |
| `fit(model, data)`                         | Add data to a workflow to build a fitted model |
| `predict(fitted_model, new_obs)`           | Predict values based on model and data         |
| `prep(recipe)`                             | Prepares data for preprocessing                |
| `nearest_neighbor(weight_func, neighbors)` | Specify that the model is K-Nearest-Neighbor   |
| `recipe(formula, data)`                    | Prepares data for modelling                    |
| `set_engine(engine)`                       | Specify package to fit the model               |
| `set_mode(mode)`                           | Specify modelling context used                 |
| `set.seed(n)`                              | Make randomization reproducible                |
| `step_center(recipe)`                      | Center variables in recipe                     |
| `step_rm(recipe)`                          | Removes specified variables                    |
| `step_scale(recipe)`                       | Scale variables in recipe                      |
| `workflow()`                               | Create workflow                                |

The functions below extend the above table for material in Week 8 (`classification2`) and beyond.

| Function                               | Description                                                                               |
| -------------------------------------- | ----------------------------------------------------------------------------------------- |
| `apparent(data)`                       | Sampling for the apparent error rate                                                      |
| `augment(fit, data)`                   | Add predictions/residuals/cluster assignments to dataframe                                |
| `collect_metrics(fitted_model)`        | Aggregate the mean and standard error of the model's accuracy across the folds            |
| `conf_mat(data, truth, estimate)`      | Computes and returns the confusion matrix                                                 |
| `fit_resamples(model, resamples)`      | Runs cross-validation on each train/validation split to build a fitted model              |
| `glance(fitted_model)`                 | Obtain total WSSD of a cluster model                                                      |
| `initial_split(data, prop, strata)`    | Splits the data                                                                           |
| `k_means(num_clusters)`                | Specify that the model is kmeans clustering                                               |
| `kmeans(data, centers, nstart)`        | Runs k-means clustering on the given data for the specified number of clusters and starts |
| `list(objects)`                        | Create a list of elements of different types                                              |
| `linear_reg()`                         | Specify that the model is linear regression                                               |
| `metrics(data, truth, estimate)`       | Returns the model's accuracy metrics                                                      |
| `testing(data)`                        | extract testing data                                                                      |
| `training(data)`                       | extract training data                                                                     |
| `tune()`                               | Tune neighbors                                                                            |
| `tune_cluster(model, resamples, grid)` | Run kmeans on multimple resamples of data                                                 |
| `tune_grid(model, resamples, grid)`    | Fit the model for each value in a range of parameter values                               |
| `unlist(list)`                         | Convert a list to a vector                                                                |
| `unnest(tbl, list_column)`             | Expand a column containing a list of tibbles into rows and columns                        |
| `vfold_cv(data, v, strata)`            | Perform cross validation                                                                  |

## Inference

| Function                                 | Description                                                                 |
| ---------------------------------------- | --------------------------------------------------------------------------- |
| `quantile(data, percentiles)`            | Finds the specified percentiles in the given data                           |
| `rep_sample_n(tbl, size, reps, replace)` | Takes samples of the table according to the size, reps, and replace options |
| `sample_n(tbl, num)`                     | Random selects the specified number of rows from the table                  |


```R
library(tidyverse)
library(tidymodels)
```


```R
marathon <- read_csv("data/marathon.csv") |>
  mutate(
      female = as_factor(female),
      footwear = as_factor(footwear),
      group = as_factor(group),
      injury = as_factor(injury),
      mf_di = as_factor(mf_di),
      sprint = as_factor(sprint)
  )

marathon |> head()
```

    [1mRows: [22m[34m929[39m [1mColumns: [22m[34m13[39m
    [36mâ”€â”€[39m [1mColumn specification[22m [36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[39m
    [1mDelimiter:[22m ","
    [32mdbl[39m (13): age, bmi, female, footwear, group, injury, mf_d, mf_di, mf_ti, max...
    
    [36mâ„¹[39m Use `spec()` to retrieve the full column specification for this data.
    [36mâ„¹[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.



<table class="dataframe">
<caption>A tibble: 6 Ã— 13</caption>
<thead>
	<tr><th scope=col>age</th><th scope=col>bmi</th><th scope=col>female</th><th scope=col>footwear</th><th scope=col>group</th><th scope=col>injury</th><th scope=col>mf_d</th><th scope=col>mf_di</th><th scope=col>mf_ti</th><th scope=col>max</th><th scope=col>sprint</th><th scope=col>mf_s</th><th scope=col>time_hrs</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>35</td><td>23.59232</td><td>0</td><td>2</td><td>1</td><td>2</td><td>42195</td><td>4</td><td>10295</td><td>60</td><td>1</td><td>4.098592</td><td>2.859722</td></tr>
	<tr><td>33</td><td>22.51830</td><td>0</td><td>2</td><td>2</td><td>2</td><td>42195</td><td>3</td><td>12292</td><td>50</td><td>0</td><td>3.432720</td><td>3.414444</td></tr>
	<tr><td>38</td><td>25.56031</td><td>0</td><td>2</td><td>3</td><td>1</td><td>42195</td><td>4</td><td>10980</td><td>65</td><td>0</td><td>3.842896</td><td>3.050000</td></tr>
	<tr><td>34</td><td>22.60793</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>3</td><td>10694</td><td>88</td><td>1</td><td>3.945670</td><td>2.970556</td></tr>
	<tr><td>39</td><td>24.97484</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>2</td><td>13452</td><td>51</td><td>0</td><td>3.136708</td><td>3.736667</td></tr>
	<tr><td>33</td><td>24.30183</td><td>1</td><td>2</td><td>2</td><td>1</td><td>42195</td><td>3</td><td>14940</td><td>40</td><td>0</td><td>2.824297</td><td>4.150000</td></tr>
</tbody>
</table>




```R
# use knn to fit the model on everything
k5 <- nearest_neighbor(weight_func = "rectangular", neighbors = 5) |>
    set_engine("kknn") |>
    set_mode("classification")
k5
```


    K-Nearest Neighbor Model Specification (classification)
    
    Main Arguments:
      neighbors = 5
      weight_func = rectangular
    
    Computational engine: kknn 




```R
r_marathon <- recipe(female ~ max, data = marathon)
r_marathon
```

    
    
    [36mâ”€â”€[39m [1mRecipe[22m [36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[39m
    
    
    
    â”€â”€ Inputs 
    
    Number of variables by role
    
    outcome:   1
    predictor: 1
    



```R
f_knn <- workflow() |>
    add_recipe(r_marathon) |>
    add_model(k5) |>
    fit(data = marathon)
f_knn
```


    â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    [3mPreprocessor:[23m Recipe
    [3mModel:[23m nearest_neighbor()
    
    â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    0 Recipe Steps
    
    â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Call:
    kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(5,     data, 5), kernel = ~"rectangular")
    
    Type of response variable: nominal
    Minimal misclassification: 0.4036598
    Best kernel: rectangular
    Best k: 5



```R
predict(object = f_knn, new_data = marathon) |> head()
```


<table class="dataframe">
<caption>A tibble: 6 Ã— 1</caption>
<thead>
	<tr><th scope=col>.pred_class</th></tr>
	<tr><th scope=col>&lt;fct&gt;</th></tr>
</thead>
<tbody>
	<tr><td>0</td></tr>
	<tr><td>1</td></tr>
	<tr><td>0</td></tr>
	<tr><td>0</td></tr>
	<tr><td>0</td></tr>
	<tr><td>0</td></tr>
</tbody>
</table>




```R
marathon |> head()
```


<table class="dataframe">
<caption>A tibble: 6 Ã— 13</caption>
<thead>
	<tr><th scope=col>age</th><th scope=col>bmi</th><th scope=col>female</th><th scope=col>footwear</th><th scope=col>group</th><th scope=col>injury</th><th scope=col>mf_d</th><th scope=col>mf_di</th><th scope=col>mf_ti</th><th scope=col>max</th><th scope=col>sprint</th><th scope=col>mf_s</th><th scope=col>time_hrs</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>35</td><td>23.59232</td><td>0</td><td>2</td><td>1</td><td>2</td><td>42195</td><td>4</td><td>10295</td><td>60</td><td>1</td><td>4.098592</td><td>2.859722</td></tr>
	<tr><td>33</td><td>22.51830</td><td>0</td><td>2</td><td>2</td><td>2</td><td>42195</td><td>3</td><td>12292</td><td>50</td><td>0</td><td>3.432720</td><td>3.414444</td></tr>
	<tr><td>38</td><td>25.56031</td><td>0</td><td>2</td><td>3</td><td>1</td><td>42195</td><td>4</td><td>10980</td><td>65</td><td>0</td><td>3.842896</td><td>3.050000</td></tr>
	<tr><td>34</td><td>22.60793</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>3</td><td>10694</td><td>88</td><td>1</td><td>3.945670</td><td>2.970556</td></tr>
	<tr><td>39</td><td>24.97484</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>2</td><td>13452</td><td>51</td><td>0</td><td>3.136708</td><td>3.736667</td></tr>
	<tr><td>33</td><td>24.30183</td><td>1</td><td>2</td><td>2</td><td>1</td><td>42195</td><td>3</td><td>14940</td><td>40</td><td>0</td><td>2.824297</td><td>4.150000</td></tr>
</tbody>
</table>




```R
bind_cols(marathon, predict(object = f_knn, new_data = marathon)) |> head()
```


<table class="dataframe">
<caption>A tibble: 6 Ã— 14</caption>
<thead>
	<tr><th scope=col>age</th><th scope=col>bmi</th><th scope=col>female</th><th scope=col>footwear</th><th scope=col>group</th><th scope=col>injury</th><th scope=col>mf_d</th><th scope=col>mf_di</th><th scope=col>mf_ti</th><th scope=col>max</th><th scope=col>sprint</th><th scope=col>mf_s</th><th scope=col>time_hrs</th><th scope=col>.pred_class</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>
</thead>
<tbody>
	<tr><td>35</td><td>23.59232</td><td>0</td><td>2</td><td>1</td><td>2</td><td>42195</td><td>4</td><td>10295</td><td>60</td><td>1</td><td>4.098592</td><td>2.859722</td><td>0</td></tr>
	<tr><td>33</td><td>22.51830</td><td>0</td><td>2</td><td>2</td><td>2</td><td>42195</td><td>3</td><td>12292</td><td>50</td><td>0</td><td>3.432720</td><td>3.414444</td><td>1</td></tr>
	<tr><td>38</td><td>25.56031</td><td>0</td><td>2</td><td>3</td><td>1</td><td>42195</td><td>4</td><td>10980</td><td>65</td><td>0</td><td>3.842896</td><td>3.050000</td><td>0</td></tr>
	<tr><td>34</td><td>22.60793</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>3</td><td>10694</td><td>88</td><td>1</td><td>3.945670</td><td>2.970556</td><td>0</td></tr>
	<tr><td>39</td><td>24.97484</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>2</td><td>13452</td><td>51</td><td>0</td><td>3.136708</td><td>3.736667</td><td>0</td></tr>
	<tr><td>33</td><td>24.30183</td><td>1</td><td>2</td><td>2</td><td>1</td><td>42195</td><td>3</td><td>14940</td><td>40</td><td>0</td><td>2.824297</td><td>4.150000</td><td>0</td></tr>
</tbody>
</table>




```R
marathon |>
    bind_cols(predict(f_knn, marathon)) |>
    count(female, .pred_class)
```


<table class="dataframe">
<caption>A tibble: 4 Ã— 3</caption>
<thead>
	<tr><th scope=col>female</th><th scope=col>.pred_class</th><th scope=col>n</th></tr>
	<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>
</thead>
<tbody>
	<tr><td>0</td><td>0</td><td>485</td></tr>
	<tr><td>0</td><td>1</td><td>108</td></tr>
	<tr><td>1</td><td>0</td><td>247</td></tr>
	<tr><td>1</td><td>1</td><td> 89</td></tr>
</tbody>
</table>




```R
marathon |>
    bind_cols(predict(f_knn, marathon)) |>
    conf_mat(female, .pred_class)
```


              Truth
    Prediction   0   1
             0 485 247
             1 108  89



```R
seq(from = 1, to = 10, by = 1)
```


<style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li><li>7</li><li>8</li><li>9</li><li>10</li></ol>




```R
c(1, 3, 5,7, 9, 20)
```


<style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>1</li><li>3</li><li>5</li><li>7</li><li>9</li><li>20</li></ol>




```R
1:5
```


<style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li></ol>




```R
# optimal value of k
ks <- tibble(neighbors = c(1, 3, 5, 7, 9, 20))
ks
```


<table class="dataframe">
<caption>A tibble: 6 Ã— 1</caption>
<thead>
	<tr><th scope=col>neighbors</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td> 1</td></tr>
	<tr><td> 3</td></tr>
	<tr><td> 5</td></tr>
	<tr><td> 7</td></tr>
	<tr><td> 9</td></tr>
	<tr><td>20</td></tr>
</tbody>
</table>




```R
k_multi <- nearest_neighbor(weight_func = "rectangular", neighbors = tune()) |>
    set_engine("kknn") |>
    set_mode("classification")
k_multi
```


    K-Nearest Neighbor Model Specification (classification)
    
    Main Arguments:
      neighbors = tune()
      weight_func = rectangular
    
    Computational engine: kknn 




```R
marathon |> head()
```


<table class="dataframe">
<caption>A tibble: 6 Ã— 13</caption>
<thead>
	<tr><th scope=col>age</th><th scope=col>bmi</th><th scope=col>female</th><th scope=col>footwear</th><th scope=col>group</th><th scope=col>injury</th><th scope=col>mf_d</th><th scope=col>mf_di</th><th scope=col>mf_ti</th><th scope=col>max</th><th scope=col>sprint</th><th scope=col>mf_s</th><th scope=col>time_hrs</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>35</td><td>23.59232</td><td>0</td><td>2</td><td>1</td><td>2</td><td>42195</td><td>4</td><td>10295</td><td>60</td><td>1</td><td>4.098592</td><td>2.859722</td></tr>
	<tr><td>33</td><td>22.51830</td><td>0</td><td>2</td><td>2</td><td>2</td><td>42195</td><td>3</td><td>12292</td><td>50</td><td>0</td><td>3.432720</td><td>3.414444</td></tr>
	<tr><td>38</td><td>25.56031</td><td>0</td><td>2</td><td>3</td><td>1</td><td>42195</td><td>4</td><td>10980</td><td>65</td><td>0</td><td>3.842896</td><td>3.050000</td></tr>
	<tr><td>34</td><td>22.60793</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>3</td><td>10694</td><td>88</td><td>1</td><td>3.945670</td><td>2.970556</td></tr>
	<tr><td>39</td><td>24.97484</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>2</td><td>13452</td><td>51</td><td>0</td><td>3.136708</td><td>3.736667</td></tr>
	<tr><td>33</td><td>24.30183</td><td>1</td><td>2</td><td>2</td><td>1</td><td>42195</td><td>3</td><td>14940</td><td>40</td><td>0</td><td>2.824297</td><td>4.150000</td></tr>
</tbody>
</table>




```R
r_marathon_standard <- recipe(female ~ max, data = marathon) |>
    step_center(all_predictors()) |>
    step_scale(all_numeric_predictors())
r_marathon_standard
```

    
    
    [36mâ”€â”€[39m [1mRecipe[22m [36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[39m
    
    
    
    â”€â”€ Inputs 
    
    Number of variables by role
    
    outcome:   1
    predictor: 1
    
    
    
    â”€â”€ Operations 
    
    [36mâ€¢[39m Centering for: [34mall_predictors()[39m
    
    [36mâ€¢[39m Scaling for: [34mall_numeric_predictors()[39m
    



```R
data_vfold <- vfold_cv(marathon, v = 7, strata = female)
```


```R
results <- workflow() |>
    add_recipe(r_marathon_standard) |>
    add_model(k_multi) |>
    tune_grid(resamples = data_vfold, grid = ks) |>
    collect_metrics()
```


```R
accuracies <- results |>
   filter(.metric == "accuracy")
accuracies
```


<table class="dataframe">
<caption>A tibble: 6 Ã— 7</caption>
<thead>
	<tr><th scope=col>neighbors</th><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>mean</th><th scope=col>n</th><th scope=col>std_err</th><th scope=col>.config</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>
</thead>
<tbody>
	<tr><td> 1</td><td>accuracy</td><td>binary</td><td>0.5134346</td><td>7</td><td>0.01672894</td><td>Preprocessor1_Model1</td></tr>
	<tr><td> 3</td><td>accuracy</td><td>binary</td><td>0.5855141</td><td>7</td><td>0.01262902</td><td>Preprocessor1_Model2</td></tr>
	<tr><td> 5</td><td>accuracy</td><td>binary</td><td>0.5790694</td><td>7</td><td>0.01248634</td><td>Preprocessor1_Model3</td></tr>
	<tr><td> 7</td><td>accuracy</td><td>binary</td><td>0.5844644</td><td>7</td><td>0.00986704</td><td>Preprocessor1_Model4</td></tr>
	<tr><td> 9</td><td>accuracy</td><td>binary</td><td>0.5973863</td><td>7</td><td>0.01493324</td><td>Preprocessor1_Model5</td></tr>
	<tr><td>20</td><td>accuracy</td><td>binary</td><td>0.6071022</td><td>7</td><td>0.01044979</td><td>Preprocessor1_Model6</td></tr>
</tbody>
</table>




```R
ggplot(accuracies, aes(x = neighbors, y = mean)) + geom_point() + geom_line()
```


    
![svg](output_20_0.svg)
    



```R
# how do we make sure we can predict well?
```


```R
marathon |> head()
```


<table class="dataframe">
<caption>A tibble: 6 Ã— 13</caption>
<thead>
	<tr><th scope=col>age</th><th scope=col>bmi</th><th scope=col>female</th><th scope=col>footwear</th><th scope=col>group</th><th scope=col>injury</th><th scope=col>mf_d</th><th scope=col>mf_di</th><th scope=col>mf_ti</th><th scope=col>max</th><th scope=col>sprint</th><th scope=col>mf_s</th><th scope=col>time_hrs</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>35</td><td>23.59232</td><td>0</td><td>2</td><td>1</td><td>2</td><td>42195</td><td>4</td><td>10295</td><td>60</td><td>1</td><td>4.098592</td><td>2.859722</td></tr>
	<tr><td>33</td><td>22.51830</td><td>0</td><td>2</td><td>2</td><td>2</td><td>42195</td><td>3</td><td>12292</td><td>50</td><td>0</td><td>3.432720</td><td>3.414444</td></tr>
	<tr><td>38</td><td>25.56031</td><td>0</td><td>2</td><td>3</td><td>1</td><td>42195</td><td>4</td><td>10980</td><td>65</td><td>0</td><td>3.842896</td><td>3.050000</td></tr>
	<tr><td>34</td><td>22.60793</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>3</td><td>10694</td><td>88</td><td>1</td><td>3.945670</td><td>2.970556</td></tr>
	<tr><td>39</td><td>24.97484</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>2</td><td>13452</td><td>51</td><td>0</td><td>3.136708</td><td>3.736667</td></tr>
	<tr><td>33</td><td>24.30183</td><td>1</td><td>2</td><td>2</td><td>1</td><td>42195</td><td>3</td><td>14940</td><td>40</td><td>0</td><td>2.824297</td><td>4.150000</td></tr>
</tbody>
</table>




```R
# split the data
set.seed(4242)

m_split <- initial_split(marathon, prop = 0.75, strata = female)
m_train <- training(m_split)
m_test <- testing(m_split)
```


```R
m_recipe <- recipe(female ~ max, data = marathon) %>% # mistake of using full marathon
  step_scale(all_numeric_predictors()) |>
  step_center(all_numeric_predictors())

knn_spec <- nearest_neighbor(weight_func = "rectangular", neighbors = 20) |>
  set_engine("kknn") %>%
  set_mode("classification")

knn_fit <- workflow() |>
  add_recipe(m_recipe) |>
  add_model(knn_spec) |>
  fit(data = marathon)

knn_fit
```


    â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    [3mPreprocessor:[23m Recipe
    [3mModel:[23m nearest_neighbor()
    
    â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    2 Recipe Steps
    
    â€¢ step_scale()
    â€¢ step_center()
    
    â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Call:
    kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(20,     data, 5), kernel = ~"rectangular")
    
    Type of response variable: nominal
    Minimal misclassification: 0.3659849
    Best kernel: rectangular
    Best k: 20



```R
predictions_1 <- predict(knn_fit, marathon) %>%
  bind_cols(marathon)
head(predictions_1)

predictions_1 %>%
  metrics(truth = female, estimate = .pred_class)

```


<table class="dataframe">
<caption>A tibble: 6 Ã— 14</caption>
<thead>
	<tr><th scope=col>.pred_class</th><th scope=col>age</th><th scope=col>bmi</th><th scope=col>female</th><th scope=col>footwear</th><th scope=col>group</th><th scope=col>injury</th><th scope=col>mf_d</th><th scope=col>mf_di</th><th scope=col>mf_ti</th><th scope=col>max</th><th scope=col>sprint</th><th scope=col>mf_s</th><th scope=col>time_hrs</th></tr>
	<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>0</td><td>35</td><td>23.59232</td><td>0</td><td>2</td><td>1</td><td>2</td><td>42195</td><td>4</td><td>10295</td><td>60</td><td>1</td><td>4.098592</td><td>2.859722</td></tr>
	<tr><td>0</td><td>33</td><td>22.51830</td><td>0</td><td>2</td><td>2</td><td>2</td><td>42195</td><td>3</td><td>12292</td><td>50</td><td>0</td><td>3.432720</td><td>3.414444</td></tr>
	<tr><td>0</td><td>38</td><td>25.56031</td><td>0</td><td>2</td><td>3</td><td>1</td><td>42195</td><td>4</td><td>10980</td><td>65</td><td>0</td><td>3.842896</td><td>3.050000</td></tr>
	<tr><td>0</td><td>34</td><td>22.60793</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>3</td><td>10694</td><td>88</td><td>1</td><td>3.945670</td><td>2.970556</td></tr>
	<tr><td>0</td><td>39</td><td>24.97484</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>2</td><td>13452</td><td>51</td><td>0</td><td>3.136708</td><td>3.736667</td></tr>
	<tr><td>0</td><td>33</td><td>24.30183</td><td>1</td><td>2</td><td>2</td><td>1</td><td>42195</td><td>3</td><td>14940</td><td>40</td><td>0</td><td>2.824297</td><td>4.150000</td></tr>
</tbody>
</table>




<table class="dataframe">
<caption>A tibble: 2 Ã— 3</caption>
<thead>
	<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>accuracy</td><td>binary</td><td>0.63293864</td></tr>
	<tr><td>kap     </td><td>binary</td><td>0.07568123</td></tr>
</tbody>
</table>




```R
recipe_train <- recipe(female ~ max, data = m_train) %>% # use train
  step_scale(all_numeric_predictors()) %>%
  step_center(all_numeric_predictors())

recipe_train

knn_fit_train <- workflow() %>%
  add_recipe(recipe_train) %>%
  add_model(knn_spec) %>%
  fit(data = m_train)

knn_fit_train

predictions_2 <- predict(knn_fit_train, m_train) %>% # predict on train
  bind_cols(m_train)
head(predictions_2)

predictions_2 %>%
  metrics(truth = female, estimate = .pred_class)
```

    
    
    [36mâ”€â”€[39m [1mRecipe[22m [36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[39m
    
    
    
    â”€â”€ Inputs 
    
    Number of variables by role
    
    outcome:   1
    predictor: 1
    
    
    
    â”€â”€ Operations 
    
    [36mâ€¢[39m Scaling for: [34mall_numeric_predictors()[39m
    
    [36mâ€¢[39m Centering for: [34mall_numeric_predictors()[39m
    



    â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    [3mPreprocessor:[23m Recipe
    [3mModel:[23m nearest_neighbor()
    
    â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    2 Recipe Steps
    
    â€¢ step_scale()
    â€¢ step_center()
    
    â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Call:
    kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(20,     data, 5), kernel = ~"rectangular")
    
    Type of response variable: nominal
    Minimal misclassification: 0.3635057
    Best kernel: rectangular
    Best k: 20



<table class="dataframe">
<caption>A tibble: 6 Ã— 14</caption>
<thead>
	<tr><th scope=col>.pred_class</th><th scope=col>age</th><th scope=col>bmi</th><th scope=col>female</th><th scope=col>footwear</th><th scope=col>group</th><th scope=col>injury</th><th scope=col>mf_d</th><th scope=col>mf_di</th><th scope=col>mf_ti</th><th scope=col>max</th><th scope=col>sprint</th><th scope=col>mf_s</th><th scope=col>time_hrs</th></tr>
	<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>0</td><td>35</td><td>23.59232</td><td>0</td><td>2</td><td>1</td><td>2</td><td>42195</td><td>4</td><td>10295</td><td>60</td><td>1</td><td>4.098592</td><td>2.859722</td></tr>
	<tr><td>0</td><td>33</td><td>22.51830</td><td>0</td><td>2</td><td>2</td><td>2</td><td>42195</td><td>3</td><td>12292</td><td>50</td><td>0</td><td>3.432720</td><td>3.414444</td></tr>
	<tr><td>0</td><td>38</td><td>25.56031</td><td>0</td><td>2</td><td>3</td><td>1</td><td>42195</td><td>4</td><td>10980</td><td>65</td><td>0</td><td>3.842896</td><td>3.050000</td></tr>
	<tr><td>0</td><td>34</td><td>22.60793</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>3</td><td>10694</td><td>88</td><td>1</td><td>3.945670</td><td>2.970556</td></tr>
	<tr><td>0</td><td>39</td><td>24.97484</td><td>0</td><td>2</td><td>1</td><td>1</td><td>42195</td><td>2</td><td>13452</td><td>51</td><td>0</td><td>3.136708</td><td>3.736667</td></tr>
	<tr><td>0</td><td>34</td><td>24.57002</td><td>0</td><td>1</td><td>3</td><td>1</td><td>42195</td><td>3</td><td>10747</td><td>75</td><td>1</td><td>3.926212</td><td>2.985278</td></tr>
</tbody>
</table>




<table class="dataframe">
<caption>A tibble: 2 Ã— 3</caption>
<thead>
	<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>accuracy</td><td>binary</td><td>0.64080460</td></tr>
	<tr><td>kap     </td><td>binary</td><td>0.03333333</td></tr>
</tbody>
</table>




```R
# do it correctly

recipe_train <- recipe(female ~ max, data = marathon) |> # use train (good)
  step_scale(all_numeric_predictors()) |>
  step_center(all_numeric_predictors())

recipe_train

knn_fit_train <- workflow() |>
  add_recipe(recipe_train) |>
  add_model(knn_spec) |>
  fit(data = m_train) # fit on train (good)

knn_fit_train

predictions_3 <- predict(knn_fit_train, m_test) |> # predict on test (good)
  bind_cols(m_test)
head(predictions_3)

predictions_3 |>
  metrics(truth = female, estimate = .pred_class)
```

    
    
    [36mâ”€â”€[39m [1mRecipe[22m [36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[39m
    
    
    
    â”€â”€ Inputs 
    
    Number of variables by role
    
    outcome:   1
    predictor: 1
    
    
    
    â”€â”€ Operations 
    
    [36mâ€¢[39m Scaling for: [34mall_numeric_predictors()[39m
    
    [36mâ€¢[39m Centering for: [34mall_numeric_predictors()[39m
    



    â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    [3mPreprocessor:[23m Recipe
    [3mModel:[23m nearest_neighbor()
    
    â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    2 Recipe Steps
    
    â€¢ step_scale()
    â€¢ step_center()
    
    â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Call:
    kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(20,     data, 5), kernel = ~"rectangular")
    
    Type of response variable: nominal
    Minimal misclassification: 0.3635057
    Best kernel: rectangular
    Best k: 20



<table class="dataframe">
<caption>A tibble: 6 Ã— 14</caption>
<thead>
	<tr><th scope=col>.pred_class</th><th scope=col>age</th><th scope=col>bmi</th><th scope=col>female</th><th scope=col>footwear</th><th scope=col>group</th><th scope=col>injury</th><th scope=col>mf_d</th><th scope=col>mf_di</th><th scope=col>mf_ti</th><th scope=col>max</th><th scope=col>sprint</th><th scope=col>mf_s</th><th scope=col>time_hrs</th></tr>
	<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>0</td><td>24</td><td>22.53944</td><td>1</td><td>2</td><td>2</td><td>1</td><td>42195</td><td>4</td><td>15420</td><td>30</td><td>0</td><td>2.736381</td><td>4.283333</td></tr>
	<tr><td>0</td><td>52</td><td>23.80480</td><td>0</td><td>1</td><td>1</td><td>1</td><td>42195</td><td>4</td><td>13257</td><td>40</td><td>1</td><td>3.182847</td><td>3.682500</td></tr>
	<tr><td>0</td><td>33</td><td>28.20037</td><td>1</td><td>2</td><td>2</td><td>1</td><td>42195</td><td>3</td><td>18484</td><td>15</td><td>0</td><td>2.282785</td><td>5.134444</td></tr>
	<tr><td>0</td><td>27</td><td>20.77415</td><td>1</td><td>2</td><td>2</td><td>1</td><td>42195</td><td>2</td><td>12095</td><td>70</td><td>1</td><td>3.488632</td><td>3.359722</td></tr>
	<tr><td>0</td><td>28</td><td>20.91324</td><td>1</td><td>1</td><td>1</td><td>1</td><td>42195</td><td>2</td><td>10888</td><td>86</td><td>1</td><td>3.875367</td><td>3.024444</td></tr>
	<tr><td>0</td><td>31</td><td>24.52616</td><td>0</td><td>1</td><td>3</td><td>1</td><td>42195</td><td>2</td><td>10778</td><td> 7</td><td>0</td><td>3.914919</td><td>2.993889</td></tr>
</tbody>
</table>




<table class="dataframe">
<caption>A tibble: 2 Ã— 3</caption>
<thead>
	<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>accuracy</td><td>binary</td><td> 0.63090129</td></tr>
	<tr><td>kap     </td><td>binary</td><td>-0.01038725</td></tr>
</tbody>
</table>




```R
predictions_1 %>%
  metrics(truth = female, estimate = .pred_class)

predictions_2 %>%
  metrics(truth = female, estimate = .pred_class)

predictions_3 %>%
  metrics(truth = female, estimate = .pred_class)
```


<table class="dataframe">
<caption>A tibble: 2 Ã— 3</caption>
<thead>
	<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>accuracy</td><td>binary</td><td>0.63293864</td></tr>
	<tr><td>kap     </td><td>binary</td><td>0.07568123</td></tr>
</tbody>
</table>




<table class="dataframe">
<caption>A tibble: 2 Ã— 3</caption>
<thead>
	<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>accuracy</td><td>binary</td><td>0.64080460</td></tr>
	<tr><td>kap     </td><td>binary</td><td>0.03333333</td></tr>
</tbody>
</table>




<table class="dataframe">
<caption>A tibble: 2 Ã— 3</caption>
<thead>
	<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>accuracy</td><td>binary</td><td> 0.63090129</td></tr>
	<tr><td>kap     </td><td>binary</td><td>-0.01038725</td></tr>
</tbody>
</table>




```R
# regression (knn and linear)
```


```R
set.seed(424242)
m_split <- initial_split(marathon, prop = 0.75, strata = female)
m_train <- training(m_split)
m_test <- testing(m_split)
```


```R
marathon_spec <- nearest_neighbor(weight_func = "rectangular", neighbors = tune()) |>
                 set_engine("kknn") |>
                 set_mode("regression")
marathon_spec
```


    K-Nearest Neighbor Model Specification (regression)
    
    Main Arguments:
      neighbors = tune()
      weight_func = rectangular
    
    Computational engine: kknn 




```R
marathon |> count(female)
```


<table class="dataframe">
<caption>A tibble: 2 Ã— 2</caption>
<thead>
	<tr><th scope=col>female</th><th scope=col>n</th></tr>
	<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>
</thead>
<tbody>
	<tr><td>0</td><td>593</td></tr>
	<tr><td>1</td><td>336</td></tr>
</tbody>
</table>




```R
marathon |> pull(max) |> mean()
```


53.0012917102799



```R
m_train |> pull(max) |> mean()
```


52.7594827591667



```R
marathon_recipe <- recipe(time_hrs ~ max + female, data = m_train) |>
                   step_scale(all_numeric_predictors()) |>
                   step_center(all_numeric_predictors())

marathon_recipe
```

    
    
    [36mâ”€â”€[39m [1mRecipe[22m [36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[39m
    
    
    
    â”€â”€ Inputs 
    
    Number of variables by role
    
    outcome:   1
    predictor: 2
    
    
    
    â”€â”€ Operations 
    
    [36mâ€¢[39m Scaling for: [34mall_numeric_predictors()[39m
    
    [36mâ€¢[39m Centering for: [34mall_numeric_predictors()[39m
    



```R
gridvals <- tibble(neighbors = seq(from = 1, to = 41, by = 10))
gridvals
```


<table class="dataframe">
<caption>A tibble: 5 Ã— 1</caption>
<thead>
	<tr><th scope=col>neighbors</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td> 1</td></tr>
	<tr><td>11</td></tr>
	<tr><td>21</td></tr>
	<tr><td>31</td></tr>
	<tr><td>41</td></tr>
</tbody>
</table>




```R
marathon_vfold <- vfold_cv(m_train, v = 5, strata = time_hrs)
```


```R
marathon_workflow <- workflow() |>
                     add_recipe(marathon_recipe) |>
                     add_model(marathon_spec) |>
                     tune_grid(resamples = marathon_vfold, grid = gridvals) |>
                     collect_metrics()
marathon_workflow
```


<table class="dataframe">
<caption>A tibble: 10 Ã— 7</caption>
<thead>
	<tr><th scope=col>neighbors</th><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>mean</th><th scope=col>n</th><th scope=col>std_err</th><th scope=col>.config</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>
</thead>
<tbody>
	<tr><td> 1</td><td>rmse</td><td>standard</td><td>0.8189310</td><td>5</td><td>0.01243811</td><td>Preprocessor1_Model1</td></tr>
	<tr><td> 1</td><td>rsq </td><td>standard</td><td>0.1484223</td><td>5</td><td>0.01008181</td><td>Preprocessor1_Model1</td></tr>
	<tr><td>11</td><td>rmse</td><td>standard</td><td>0.5573217</td><td>5</td><td>0.01871256</td><td>Preprocessor1_Model2</td></tr>
	<tr><td>11</td><td>rsq </td><td>standard</td><td>0.3894622</td><td>5</td><td>0.01862499</td><td>Preprocessor1_Model2</td></tr>
	<tr><td>21</td><td>rmse</td><td>standard</td><td>0.5505424</td><td>5</td><td>0.01586727</td><td>Preprocessor1_Model3</td></tr>
	<tr><td>21</td><td>rsq </td><td>standard</td><td>0.4023609</td><td>5</td><td>0.01493617</td><td>Preprocessor1_Model3</td></tr>
	<tr><td>31</td><td>rmse</td><td>standard</td><td>0.5464866</td><td>5</td><td>0.01708139</td><td>Preprocessor1_Model4</td></tr>
	<tr><td>31</td><td>rsq </td><td>standard</td><td>0.4084444</td><td>5</td><td>0.01368831</td><td>Preprocessor1_Model4</td></tr>
	<tr><td>41</td><td>rmse</td><td>standard</td><td>0.5459294</td><td>5</td><td>0.01805168</td><td>Preprocessor1_Model5</td></tr>
	<tr><td>41</td><td>rsq </td><td>standard</td><td>0.4096833</td><td>5</td><td>0.01456921</td><td>Preprocessor1_Model5</td></tr>
</tbody>
</table>




```R
marathon_acc <- marathon_workflow |>
    filter(.metric == 'rmse')
marathon_acc
```


<table class="dataframe">
<caption>A tibble: 5 Ã— 7</caption>
<thead>
	<tr><th scope=col>neighbors</th><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>mean</th><th scope=col>n</th><th scope=col>std_err</th><th scope=col>.config</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>
</thead>
<tbody>
	<tr><td> 1</td><td>rmse</td><td>standard</td><td>0.8189310</td><td>5</td><td>0.01243811</td><td>Preprocessor1_Model1</td></tr>
	<tr><td>11</td><td>rmse</td><td>standard</td><td>0.5573217</td><td>5</td><td>0.01871256</td><td>Preprocessor1_Model2</td></tr>
	<tr><td>21</td><td>rmse</td><td>standard</td><td>0.5505424</td><td>5</td><td>0.01586727</td><td>Preprocessor1_Model3</td></tr>
	<tr><td>31</td><td>rmse</td><td>standard</td><td>0.5464866</td><td>5</td><td>0.01708139</td><td>Preprocessor1_Model4</td></tr>
	<tr><td>41</td><td>rmse</td><td>standard</td><td>0.5459294</td><td>5</td><td>0.01805168</td><td>Preprocessor1_Model5</td></tr>
</tbody>
</table>




```R
marathon_acc |>
 filter(mean == min(mean))
```


<table class="dataframe">
<caption>A tibble: 1 Ã— 7</caption>
<thead>
	<tr><th scope=col>neighbors</th><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>mean</th><th scope=col>n</th><th scope=col>std_err</th><th scope=col>.config</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>
</thead>
<tbody>
	<tr><td>41</td><td>rmse</td><td>standard</td><td>0.5459294</td><td>5</td><td>0.01805168</td><td>Preprocessor1_Model5</td></tr>
</tbody>
</table>




```R
marathon_acc |>
    slice_min(mean, n=1) 
```


<table class="dataframe">
<caption>A tibble: 1 Ã— 7</caption>
<thead>
	<tr><th scope=col>neighbors</th><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>mean</th><th scope=col>n</th><th scope=col>std_err</th><th scope=col>.config</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>
</thead>
<tbody>
	<tr><td>41</td><td>rmse</td><td>standard</td><td>0.5459294</td><td>5</td><td>0.01805168</td><td>Preprocessor1_Model5</td></tr>
</tbody>
</table>




```R
k_best <- marathon_acc |>
  filter(mean == min(mean)) |>
  pull(neighbors)
k_best
```


41



```R
marathon_best_spec <- nearest_neighbor(weight_func = "rectangular", neighbors = k_best) |>
                            set_engine("kknn") |>
                            set_mode("regression")

marathon_best_fit <- workflow() |>
                        add_recipe(marathon_recipe) |>
                        add_model(marathon_best_spec) |>
                        fit(data = m_train)

marathon_summary <- marathon_best_fit |> 
                       predict(m_test) |>
                       bind_cols(m_test) |>
                       metrics(truth = time_hrs, estimate = .pred) 
marathon_summary
```


<table class="dataframe">
<caption>A tibble: 3 Ã— 3</caption>
<thead>
	<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>rmse</td><td>standard</td><td>0.5998920</td></tr>
	<tr><td>rsq </td><td>standard</td><td>0.4184801</td></tr>
	<tr><td>mae </td><td>standard</td><td>0.4332147</td></tr>
</tbody>
</table>




```R
# mess up train/test
marathon_best_spec <- nearest_neighbor(weight_func = "rectangular", neighbors = k_best) |>
                            set_engine("kknn") |>
                            set_mode("regression")

marathon_best_fit <- workflow() |>
                        add_recipe(marathon_recipe) |>
                        add_model(marathon_best_spec) |>
                        fit(data = m_train)

marathon_summary <- marathon_best_fit |> 
                       predict(m_train) |>
                       bind_cols(m_train) |>
                       metrics(truth = time_hrs, estimate = .pred) 
marathon_summary
# rmse lower, (so a bit better. but artificial)
```


<table class="dataframe">
<caption>A tibble: 3 Ã— 3</caption>
<thead>
	<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>rmse</td><td>standard</td><td>0.5331159</td></tr>
	<tr><td>rsq </td><td>standard</td><td>0.4355620</td></tr>
	<tr><td>mae </td><td>standard</td><td>0.4054456</td></tr>
</tbody>
</table>




```R
lm_spec <- linear_reg() |>
    set_engine("lm") |>
    set_mode("regression")

# marathon_recipe
marathon_recipe <- recipe(time_hrs ~ max + female, data = m_train)

marathon_recipe

lm_mod <- workflow() |>
    add_recipe(marathon_recipe) |>
    add_model(lm_spec) |>
    fit(data = m_train)
lm_mod
```

    
    
    [36mâ”€â”€[39m [1mRecipe[22m [36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[39m
    
    
    
    â”€â”€ Inputs 
    
    Number of variables by role
    
    outcome:   1
    predictor: 2
    



    â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    [3mPreprocessor:[23m Recipe
    [3mModel:[23m linear_reg()
    
    â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    0 Recipe Steps
    
    â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Call:
    stats::lm(formula = ..y ~ ., data = data)
    
    Coefficients:
    (Intercept)          max      female1  
        4.65596     -0.02026      0.37418  




```R
lm_mod |> 
    predict(m_test) |>
    bind_cols(m_test) |>
    metrics(truth = time_hrs, estimate = .pred) 
```


<table class="dataframe">
<caption>A tibble: 3 Ã— 3</caption>
<thead>
	<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>
	<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>rmse</td><td>standard</td><td>0.6097583</td></tr>
	<tr><td>rsq </td><td>standard</td><td>0.3980943</td></tr>
	<tr><td>mae </td><td>standard</td><td>0.4446058</td></tr>
</tbody>
</table>




```R
# clustering
```


```R
mtcars_subset <- mtcars %>%
  select(mpg, disp, hp, wt)
mtcars_subset |> head()
```


<table class="dataframe">
<caption>A data.frame: 6 Ã— 4</caption>
<thead>
	<tr><th></th><th scope=col>mpg</th><th scope=col>disp</th><th scope=col>hp</th><th scope=col>wt</th></tr>
	<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>Mazda RX4</th><td>21.0</td><td>160</td><td>110</td><td>2.620</td></tr>
	<tr><th scope=row>Mazda RX4 Wag</th><td>21.0</td><td>160</td><td>110</td><td>2.875</td></tr>
	<tr><th scope=row>Datsun 710</th><td>22.8</td><td>108</td><td> 93</td><td>2.320</td></tr>
	<tr><th scope=row>Hornet 4 Drive</th><td>21.4</td><td>258</td><td>110</td><td>3.215</td></tr>
	<tr><th scope=row>Hornet Sportabout</th><td>18.7</td><td>360</td><td>175</td><td>3.440</td></tr>
	<tr><th scope=row>Valiant</th><td>18.1</td><td>225</td><td>105</td><td>3.460</td></tr>
</tbody>
</table>




```R
library(tidyclust)
r_clust <- recipe(~ ., data = mtcars_subset) |>
    step_scale(all_predictors()) |>
    step_center(all_predictors())

s_clust <- k_means(num_clusters = 4) |> # kmeans come from tidyclust
    set_engine("stats")

c_cars <- workflow() |>
    add_recipe(r_clust) |>
    add_model(s_clust) |>
    fit(data = mtcars_subset)

c_cars
```


    â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    [3mPreprocessor:[23m Recipe
    [3mModel:[23m k_means()
    
    â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    2 Recipe Steps
    
    â€¢ step_scale()
    â€¢ step_center()
    
    â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    K-means clustering with 4 clusters of sizes 12, 7, 7, 6
    
    Cluster means:
             mpg       disp         hp         wt
    4  0.1384407 -0.5707543 -0.5448163 -0.2454544
    3 -0.5483556  0.6850701  0.3400164  0.4816984
    1 -1.1077479  1.2897470  1.4839092  1.1166629
    2  1.6552394 -1.1624447 -1.0382807 -1.3738462
    
    Clustering vector:
     [1] 1 1 1 1 2 1 3 1 1 1 1 2 2 2 3 3 3 4 4 4 1 2 2 3 2 4 4 4 3 1 3 1
    
    Within cluster sum of squares by cluster:
    [1]  5.890043  1.961321 10.922714  2.262541
     (between_SS / total_SS =  83.0 %)
    
    Available components:
    
    [1] "cluster"      "centers"      "totss"        "withinss"     "tot.withinss"
    [6] "betweenss"    "size"         "iter"         "ifault"      



```R
mtcars_subset |> head()
```


<table class="dataframe">
<caption>A data.frame: 6 Ã— 4</caption>
<thead>
	<tr><th></th><th scope=col>mpg</th><th scope=col>disp</th><th scope=col>hp</th><th scope=col>wt</th></tr>
	<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>Mazda RX4</th><td>21.0</td><td>160</td><td>110</td><td>2.620</td></tr>
	<tr><th scope=row>Mazda RX4 Wag</th><td>21.0</td><td>160</td><td>110</td><td>2.875</td></tr>
	<tr><th scope=row>Datsun 710</th><td>22.8</td><td>108</td><td> 93</td><td>2.320</td></tr>
	<tr><th scope=row>Hornet 4 Drive</th><td>21.4</td><td>258</td><td>110</td><td>3.215</td></tr>
	<tr><th scope=row>Hornet Sportabout</th><td>18.7</td><td>360</td><td>175</td><td>3.440</td></tr>
	<tr><th scope=row>Valiant</th><td>18.1</td><td>225</td><td>105</td><td>3.460</td></tr>
</tbody>
</table>




```R
clustered_cars <- augment(c_cars, mtcars_subset) # really similar to bind_cols we did before
clustered_cars |> head()
```


<table class="dataframe">
<caption>A tibble: 6 Ã— 5</caption>
<thead>
	<tr><th scope=col>mpg</th><th scope=col>disp</th><th scope=col>hp</th><th scope=col>wt</th><th scope=col>.pred_cluster</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>
</thead>
<tbody>
	<tr><td>21.0</td><td>160</td><td>110</td><td>2.620</td><td>Cluster_1</td></tr>
	<tr><td>21.0</td><td>160</td><td>110</td><td>2.875</td><td>Cluster_1</td></tr>
	<tr><td>22.8</td><td>108</td><td> 93</td><td>2.320</td><td>Cluster_1</td></tr>
	<tr><td>21.4</td><td>258</td><td>110</td><td>3.215</td><td>Cluster_1</td></tr>
	<tr><td>18.7</td><td>360</td><td>175</td><td>3.440</td><td>Cluster_2</td></tr>
	<tr><td>18.1</td><td>225</td><td>105</td><td>3.460</td><td>Cluster_1</td></tr>
</tbody>
</table>




```R
ggplot(clustered_cars, aes(x = hp, y = mpg, colour = .pred_cluster)) +
  geom_point(alpha = 0.5, size = 2)
```


    
![svg](output_52_0.svg)
    



```R

```


```R
ks <- tibble(num_clusters = 1:10)

new_spec <- k_means(num_clusters = tune()) |> set_engine("stats", nstart=10)

elbow_stats <- workflow() |>
    add_recipe(r_clust) |>
    add_model(new_spec) |>
    tune_cluster(resamples = apparent(mtcars_subset), grid = ks) |> # really similar to fit resamples when doing cv
    collect_metrics() |>`
    filter(.metric == "sse_within_total") |>
    mutate(total_WSSD = mean) |>
    select(num_clusters, total_WSSD)
```


```R
?apparent
```



<table style="width: 100%;"><tr><td>apparent {rsample}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2 id='apparent'>Sampling for the Apparent Error Rate</h2>

<h3>Description</h3>

<p>When building a model on a data set and re-predicting the same data, the
performance estimate from those predictions is often called the
&quot;apparent&quot; performance of the model. This estimate can be wildly
optimistic. &quot;Apparent sampling&quot; here means that the analysis and
assessment samples are the same. These resamples are sometimes used in
the analysis of bootstrap samples and should otherwise be
avoided like old sushi.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apparent(data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apparent_:_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="apparent_:_...">...</code></td>
<td>
<p>These dots are for future extensions and must be empty.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with a single row and classes <code>apparent</code>,
<code>rset</code>, <code>tbl_df</code>, <code>tbl</code>, and <code>data.frame</code>. The
results include a column for the data split objects and one column
called <code>id</code> that has a character string with the resample identifier.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>apparent(mtcars)
</code></pre>

<hr /><div style="text-align: center;">[Package <em>rsample</em> version 1.2.0 ]</div>
</div>



```R
elbow_stats
```


<table class="dataframe">
<caption>A tibble: 10 Ã— 2</caption>
<thead>
	<tr><th scope=col>num_clusters</th><th scope=col>total_WSSD</th></tr>
	<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td> 1</td><td>124.000000</td></tr>
	<tr><td> 2</td><td> 46.072608</td></tr>
	<tr><td> 3</td><td> 29.402405</td></tr>
	<tr><td> 4</td><td> 18.369057</td></tr>
	<tr><td> 5</td><td> 12.209820</td></tr>
	<tr><td> 6</td><td>  9.581504</td></tr>
	<tr><td> 7</td><td>  8.444016</td></tr>
	<tr><td> 8</td><td>  7.184407</td></tr>
	<tr><td> 9</td><td>  6.273651</td></tr>
	<tr><td>10</td><td>  5.432449</td></tr>
</tbody>
</table>




```R
ggplot(elbow_stats, aes(x = num_clusters, y = total_WSSD)) +
  geom_point() +
  geom_line()
```


    
![svg](output_57_0.svg)
    



```R
# inference
```


```R
library(tidyverse)
library(tidymodels)

# inference example -----

mtcars

mtcars_sample <- mtcars |> sample_n(size = 16)

mtcars_sample

```


<table class="dataframe">
<caption>A data.frame: 32 Ã— 11</caption>
<thead>
	<tr><th></th><th scope=col>mpg</th><th scope=col>cyl</th><th scope=col>disp</th><th scope=col>hp</th><th scope=col>drat</th><th scope=col>wt</th><th scope=col>qsec</th><th scope=col>vs</th><th scope=col>am</th><th scope=col>gear</th><th scope=col>carb</th></tr>
	<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>Mazda RX4</th><td>21.0</td><td>6</td><td>160.0</td><td>110</td><td>3.90</td><td>2.620</td><td>16.46</td><td>0</td><td>1</td><td>4</td><td>4</td></tr>
	<tr><th scope=row>Mazda RX4 Wag</th><td>21.0</td><td>6</td><td>160.0</td><td>110</td><td>3.90</td><td>2.875</td><td>17.02</td><td>0</td><td>1</td><td>4</td><td>4</td></tr>
	<tr><th scope=row>Datsun 710</th><td>22.8</td><td>4</td><td>108.0</td><td> 93</td><td>3.85</td><td>2.320</td><td>18.61</td><td>1</td><td>1</td><td>4</td><td>1</td></tr>
	<tr><th scope=row>Hornet 4 Drive</th><td>21.4</td><td>6</td><td>258.0</td><td>110</td><td>3.08</td><td>3.215</td><td>19.44</td><td>1</td><td>0</td><td>3</td><td>1</td></tr>
	<tr><th scope=row>Hornet Sportabout</th><td>18.7</td><td>8</td><td>360.0</td><td>175</td><td>3.15</td><td>3.440</td><td>17.02</td><td>0</td><td>0</td><td>3</td><td>2</td></tr>
	<tr><th scope=row>Valiant</th><td>18.1</td><td>6</td><td>225.0</td><td>105</td><td>2.76</td><td>3.460</td><td>20.22</td><td>1</td><td>0</td><td>3</td><td>1</td></tr>
	<tr><th scope=row>Duster 360</th><td>14.3</td><td>8</td><td>360.0</td><td>245</td><td>3.21</td><td>3.570</td><td>15.84</td><td>0</td><td>0</td><td>3</td><td>4</td></tr>
	<tr><th scope=row>Merc 240D</th><td>24.4</td><td>4</td><td>146.7</td><td> 62</td><td>3.69</td><td>3.190</td><td>20.00</td><td>1</td><td>0</td><td>4</td><td>2</td></tr>
	<tr><th scope=row>Merc 230</th><td>22.8</td><td>4</td><td>140.8</td><td> 95</td><td>3.92</td><td>3.150</td><td>22.90</td><td>1</td><td>0</td><td>4</td><td>2</td></tr>
	<tr><th scope=row>Merc 280</th><td>19.2</td><td>6</td><td>167.6</td><td>123</td><td>3.92</td><td>3.440</td><td>18.30</td><td>1</td><td>0</td><td>4</td><td>4</td></tr>
	<tr><th scope=row>Merc 280C</th><td>17.8</td><td>6</td><td>167.6</td><td>123</td><td>3.92</td><td>3.440</td><td>18.90</td><td>1</td><td>0</td><td>4</td><td>4</td></tr>
	<tr><th scope=row>Merc 450SE</th><td>16.4</td><td>8</td><td>275.8</td><td>180</td><td>3.07</td><td>4.070</td><td>17.40</td><td>0</td><td>0</td><td>3</td><td>3</td></tr>
	<tr><th scope=row>Merc 450SL</th><td>17.3</td><td>8</td><td>275.8</td><td>180</td><td>3.07</td><td>3.730</td><td>17.60</td><td>0</td><td>0</td><td>3</td><td>3</td></tr>
	<tr><th scope=row>Merc 450SLC</th><td>15.2</td><td>8</td><td>275.8</td><td>180</td><td>3.07</td><td>3.780</td><td>18.00</td><td>0</td><td>0</td><td>3</td><td>3</td></tr>
	<tr><th scope=row>Cadillac Fleetwood</th><td>10.4</td><td>8</td><td>472.0</td><td>205</td><td>2.93</td><td>5.250</td><td>17.98</td><td>0</td><td>0</td><td>3</td><td>4</td></tr>
	<tr><th scope=row>Lincoln Continental</th><td>10.4</td><td>8</td><td>460.0</td><td>215</td><td>3.00</td><td>5.424</td><td>17.82</td><td>0</td><td>0</td><td>3</td><td>4</td></tr>
	<tr><th scope=row>Chrysler Imperial</th><td>14.7</td><td>8</td><td>440.0</td><td>230</td><td>3.23</td><td>5.345</td><td>17.42</td><td>0</td><td>0</td><td>3</td><td>4</td></tr>
	<tr><th scope=row>Fiat 128</th><td>32.4</td><td>4</td><td> 78.7</td><td> 66</td><td>4.08</td><td>2.200</td><td>19.47</td><td>1</td><td>1</td><td>4</td><td>1</td></tr>
	<tr><th scope=row>Honda Civic</th><td>30.4</td><td>4</td><td> 75.7</td><td> 52</td><td>4.93</td><td>1.615</td><td>18.52</td><td>1</td><td>1</td><td>4</td><td>2</td></tr>
	<tr><th scope=row>Toyota Corolla</th><td>33.9</td><td>4</td><td> 71.1</td><td> 65</td><td>4.22</td><td>1.835</td><td>19.90</td><td>1</td><td>1</td><td>4</td><td>1</td></tr>
	<tr><th scope=row>Toyota Corona</th><td>21.5</td><td>4</td><td>120.1</td><td> 97</td><td>3.70</td><td>2.465</td><td>20.01</td><td>1</td><td>0</td><td>3</td><td>1</td></tr>
	<tr><th scope=row>Dodge Challenger</th><td>15.5</td><td>8</td><td>318.0</td><td>150</td><td>2.76</td><td>3.520</td><td>16.87</td><td>0</td><td>0</td><td>3</td><td>2</td></tr>
	<tr><th scope=row>AMC Javelin</th><td>15.2</td><td>8</td><td>304.0</td><td>150</td><td>3.15</td><td>3.435</td><td>17.30</td><td>0</td><td>0</td><td>3</td><td>2</td></tr>
	<tr><th scope=row>Camaro Z28</th><td>13.3</td><td>8</td><td>350.0</td><td>245</td><td>3.73</td><td>3.840</td><td>15.41</td><td>0</td><td>0</td><td>3</td><td>4</td></tr>
	<tr><th scope=row>Pontiac Firebird</th><td>19.2</td><td>8</td><td>400.0</td><td>175</td><td>3.08</td><td>3.845</td><td>17.05</td><td>0</td><td>0</td><td>3</td><td>2</td></tr>
	<tr><th scope=row>Fiat X1-9</th><td>27.3</td><td>4</td><td> 79.0</td><td> 66</td><td>4.08</td><td>1.935</td><td>18.90</td><td>1</td><td>1</td><td>4</td><td>1</td></tr>
	<tr><th scope=row>Porsche 914-2</th><td>26.0</td><td>4</td><td>120.3</td><td> 91</td><td>4.43</td><td>2.140</td><td>16.70</td><td>0</td><td>1</td><td>5</td><td>2</td></tr>
	<tr><th scope=row>Lotus Europa</th><td>30.4</td><td>4</td><td> 95.1</td><td>113</td><td>3.77</td><td>1.513</td><td>16.90</td><td>1</td><td>1</td><td>5</td><td>2</td></tr>
	<tr><th scope=row>Ford Pantera L</th><td>15.8</td><td>8</td><td>351.0</td><td>264</td><td>4.22</td><td>3.170</td><td>14.50</td><td>0</td><td>1</td><td>5</td><td>4</td></tr>
	<tr><th scope=row>Ferrari Dino</th><td>19.7</td><td>6</td><td>145.0</td><td>175</td><td>3.62</td><td>2.770</td><td>15.50</td><td>0</td><td>1</td><td>5</td><td>6</td></tr>
	<tr><th scope=row>Maserati Bora</th><td>15.0</td><td>8</td><td>301.0</td><td>335</td><td>3.54</td><td>3.570</td><td>14.60</td><td>0</td><td>1</td><td>5</td><td>8</td></tr>
	<tr><th scope=row>Volvo 142E</th><td>21.4</td><td>4</td><td>121.0</td><td>109</td><td>4.11</td><td>2.780</td><td>18.60</td><td>1</td><td>1</td><td>4</td><td>2</td></tr>
</tbody>
</table>




<table class="dataframe">
<caption>A data.frame: 16 Ã— 11</caption>
<thead>
	<tr><th></th><th scope=col>mpg</th><th scope=col>cyl</th><th scope=col>disp</th><th scope=col>hp</th><th scope=col>drat</th><th scope=col>wt</th><th scope=col>qsec</th><th scope=col>vs</th><th scope=col>am</th><th scope=col>gear</th><th scope=col>carb</th></tr>
	<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>Ferrari Dino</th><td>19.7</td><td>6</td><td>145.0</td><td>175</td><td>3.62</td><td>2.770</td><td>15.50</td><td>0</td><td>1</td><td>5</td><td>6</td></tr>
	<tr><th scope=row>Valiant</th><td>18.1</td><td>6</td><td>225.0</td><td>105</td><td>2.76</td><td>3.460</td><td>20.22</td><td>1</td><td>0</td><td>3</td><td>1</td></tr>
	<tr><th scope=row>Mazda RX4 Wag</th><td>21.0</td><td>6</td><td>160.0</td><td>110</td><td>3.90</td><td>2.875</td><td>17.02</td><td>0</td><td>1</td><td>4</td><td>4</td></tr>
	<tr><th scope=row>Merc 450SE</th><td>16.4</td><td>8</td><td>275.8</td><td>180</td><td>3.07</td><td>4.070</td><td>17.40</td><td>0</td><td>0</td><td>3</td><td>3</td></tr>
	<tr><th scope=row>Pontiac Firebird</th><td>19.2</td><td>8</td><td>400.0</td><td>175</td><td>3.08</td><td>3.845</td><td>17.05</td><td>0</td><td>0</td><td>3</td><td>2</td></tr>
	<tr><th scope=row>Camaro Z28</th><td>13.3</td><td>8</td><td>350.0</td><td>245</td><td>3.73</td><td>3.840</td><td>15.41</td><td>0</td><td>0</td><td>3</td><td>4</td></tr>
	<tr><th scope=row>Porsche 914-2</th><td>26.0</td><td>4</td><td>120.3</td><td> 91</td><td>4.43</td><td>2.140</td><td>16.70</td><td>0</td><td>1</td><td>5</td><td>2</td></tr>
	<tr><th scope=row>Merc 450SLC</th><td>15.2</td><td>8</td><td>275.8</td><td>180</td><td>3.07</td><td>3.780</td><td>18.00</td><td>0</td><td>0</td><td>3</td><td>3</td></tr>
	<tr><th scope=row>Toyota Corona</th><td>21.5</td><td>4</td><td>120.1</td><td> 97</td><td>3.70</td><td>2.465</td><td>20.01</td><td>1</td><td>0</td><td>3</td><td>1</td></tr>
	<tr><th scope=row>Cadillac Fleetwood</th><td>10.4</td><td>8</td><td>472.0</td><td>205</td><td>2.93</td><td>5.250</td><td>17.98</td><td>0</td><td>0</td><td>3</td><td>4</td></tr>
	<tr><th scope=row>Duster 360</th><td>14.3</td><td>8</td><td>360.0</td><td>245</td><td>3.21</td><td>3.570</td><td>15.84</td><td>0</td><td>0</td><td>3</td><td>4</td></tr>
	<tr><th scope=row>Merc 450SL</th><td>17.3</td><td>8</td><td>275.8</td><td>180</td><td>3.07</td><td>3.730</td><td>17.60</td><td>0</td><td>0</td><td>3</td><td>3</td></tr>
	<tr><th scope=row>Merc 280</th><td>19.2</td><td>6</td><td>167.6</td><td>123</td><td>3.92</td><td>3.440</td><td>18.30</td><td>1</td><td>0</td><td>4</td><td>4</td></tr>
	<tr><th scope=row>AMC Javelin</th><td>15.2</td><td>8</td><td>304.0</td><td>150</td><td>3.15</td><td>3.435</td><td>17.30</td><td>0</td><td>0</td><td>3</td><td>2</td></tr>
	<tr><th scope=row>Merc 280C</th><td>17.8</td><td>6</td><td>167.6</td><td>123</td><td>3.92</td><td>3.440</td><td>18.90</td><td>1</td><td>0</td><td>4</td><td>4</td></tr>
	<tr><th scope=row>Fiat X1-9</th><td>27.3</td><td>4</td><td> 79.0</td><td> 66</td><td>4.08</td><td>1.935</td><td>18.90</td><td>1</td><td>1</td><td>4</td><td>1</td></tr>
</tbody>
</table>




```R
nrow(mtcars_sample)
```


16



```R

bootstrap_samples <- rep_sample_n(mtcars_sample, size = 16, reps = 1000, replace = TRUE)

bootstrap_sample_estimates <- bootstrap_samples %>%
  group_by(replicate) %>% # technically the data is already grouped, but i'm putting this here to be extra explicit
  summarize(avg_mpg = mean(mpg, na.rm = TRUE))
bootstrap_sample_estimates

```


<table class="dataframe">
<caption>A tibble: 1000 Ã— 2</caption>
<thead>
	<tr><th scope=col>replicate</th><th scope=col>avg_mpg</th></tr>
	<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td> 1</td><td>17.79375</td></tr>
	<tr><td> 2</td><td>18.99375</td></tr>
	<tr><td> 3</td><td>17.83750</td></tr>
	<tr><td> 4</td><td>19.40625</td></tr>
	<tr><td> 5</td><td>18.55625</td></tr>
	<tr><td> 6</td><td>18.55625</td></tr>
	<tr><td> 7</td><td>17.18750</td></tr>
	<tr><td> 8</td><td>18.95000</td></tr>
	<tr><td> 9</td><td>16.02500</td></tr>
	<tr><td>10</td><td>18.16875</td></tr>
	<tr><td>11</td><td>18.10625</td></tr>
	<tr><td>12</td><td>16.43125</td></tr>
	<tr><td>13</td><td>17.37500</td></tr>
	<tr><td>14</td><td>18.81875</td></tr>
	<tr><td>15</td><td>17.52500</td></tr>
	<tr><td>16</td><td>17.36250</td></tr>
	<tr><td>17</td><td>18.11875</td></tr>
	<tr><td>18</td><td>19.05000</td></tr>
	<tr><td>19</td><td>19.17500</td></tr>
	<tr><td>20</td><td>20.42500</td></tr>
	<tr><td>21</td><td>17.73125</td></tr>
	<tr><td>22</td><td>17.20000</td></tr>
	<tr><td>23</td><td>18.18125</td></tr>
	<tr><td>24</td><td>17.76250</td></tr>
	<tr><td>25</td><td>17.92500</td></tr>
	<tr><td>26</td><td>17.79375</td></tr>
	<tr><td>27</td><td>18.14375</td></tr>
	<tr><td>28</td><td>18.15000</td></tr>
	<tr><td>29</td><td>17.50625</td></tr>
	<tr><td>30</td><td>19.50000</td></tr>
	<tr><td>â‹®</td><td>â‹®</td></tr>
	<tr><td> 971</td><td>17.68125</td></tr>
	<tr><td> 972</td><td>18.31875</td></tr>
	<tr><td> 973</td><td>19.53125</td></tr>
	<tr><td> 974</td><td>17.24375</td></tr>
	<tr><td> 975</td><td>18.93750</td></tr>
	<tr><td> 976</td><td>17.95000</td></tr>
	<tr><td> 977</td><td>17.61250</td></tr>
	<tr><td> 978</td><td>17.95625</td></tr>
	<tr><td> 979</td><td>17.81250</td></tr>
	<tr><td> 980</td><td>16.95625</td></tr>
	<tr><td> 981</td><td>18.69375</td></tr>
	<tr><td> 982</td><td>21.27500</td></tr>
	<tr><td> 983</td><td>18.77500</td></tr>
	<tr><td> 984</td><td>19.20625</td></tr>
	<tr><td> 985</td><td>19.71250</td></tr>
	<tr><td> 986</td><td>19.81875</td></tr>
	<tr><td> 987</td><td>19.19375</td></tr>
	<tr><td> 988</td><td>18.50000</td></tr>
	<tr><td> 989</td><td>18.18750</td></tr>
	<tr><td> 990</td><td>17.76250</td></tr>
	<tr><td> 991</td><td>18.70000</td></tr>
	<tr><td> 992</td><td>18.90625</td></tr>
	<tr><td> 993</td><td>18.35625</td></tr>
	<tr><td> 994</td><td>18.04375</td></tr>
	<tr><td> 995</td><td>17.89375</td></tr>
	<tr><td> 996</td><td>18.21250</td></tr>
	<tr><td> 997</td><td>17.87500</td></tr>
	<tr><td> 998</td><td>18.38750</td></tr>
	<tr><td> 999</td><td>17.39375</td></tr>
	<tr><td>1000</td><td>19.02500</td></tr>
</tbody>
</table>




```R
ggplot(bootstrap_sample_estimates, aes(x = avg_mpg)) + geom_histogram()

bootstrap_sample_estimates %>%
    pull(avg_mpg) %>%
    mean()
```

    [1m[22m`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.



18.237625



    
![svg](output_62_2.svg)
    



```R
mtcars |>
    pull(mpg) |>
    mean()
```


20.090625



```R
s_size <- 30

mtcars_sample <- mtcars |> sample_n(size = s_size)
bootstrap_samples <- rep_sample_n(mtcars_sample, size = s_size, reps = 1000, replace = TRUE)

bootstrap_sample_estimates <- bootstrap_samples %>%
  group_by(replicate) %>% # technically the data is already grouped, but i'm putting this here to be extra explicit
  summarize(avg_mpg = mean(mpg, na.rm = TRUE))

ggplot(bootstrap_sample_estimates, aes(x = avg_mpg)) + geom_histogram()

bootstrap_sample_estimates %>%
    pull(avg_mpg) %>%
    mean()

bootstrap_sample_estimates %>%
    pull(avg_mpg) %>%
    sd()
```

    [1m[22m`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.



19.8384866666667



1.01950872541472



    
![svg](output_64_3.svg)
    



```R

```

[chat](https://www.openai.com)
[doc](http://datasciencebook.ca)

